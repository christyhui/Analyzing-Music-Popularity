wine_glm_mse = wine_cv10_glm$delta
wine_lda_acc = (1068 + 882)/3000
wine_qda_acc = (800 + 1068)/3000
wine_knn_acc = (1163 + 1082)/3000
# plot accuracies so it is easier to see
model_num = c(wine_lda_acc, wine_qda_acc, wine_knn_acc)
wine_glm_mse
plot(model_num, xlab = "Models", ylab = "Accuracy Rate", xaxt = "n")
axis(1, at = 1:3, labels = c("wine_lda_acc", "wine_qda_acc", "wine_knn_acc"))
set.seed(1128)
births = read.csv("births 10000 Ob F2021.csv")
# delete variables that will not help with predicting outcome variables
births = births[, -c(3, 4, 5, 6, 17, 18, 19)]
# omit NAs
births = na.omit(births)
# resize births so the data is more manageable
birthsNew = births[sample(nrow(births), 3000),]
names(birthsNew)[35] = "Birth.Weight"
library(car)
symbox(~Birth.Weight, data = birthsNew)
inverseResponsePlot(lm(Birth.Weight ~ ., data = birthsNew))
births_lm = lm(Birth.Weight ~., data = birthsNew)
library(stats)
back_reg = step(births_lm,
direction = "backward",
k = 2)
back_reg$terms
births_lm = lm(Birth.Weight ~., data = birthsNew)
library(stats)
back_reg = step(births_lm,
direction = "backward",
k = log(3000))
back_reg$terms
births_lm = lm(Birth.Weight ~ 1, data = birthsNew)
library(stats)
forwards_reg = step(births_lm,
scope = list(lower = ~1, upper = ~Institution.type + Plurality.of.birth + Gender + Race.of.child + Race + Age.of.father + Age.of.mother + Education.of.father..years. + Education.of.mother..years. + Total.Preg + BDead + Terms + LOutcome + Weeks + Prenatal + Trimester.Prenatal + Visits + Birth.weight.group + Marital + Birth.Attendant + Numchild + Month.Term + Year.Term + Low.Birth + RaceMom + RaceDad + Mother.Minority + Father.Minority + HispMom + HispDad + AveCigs + Smoker + AveDrink + Wt.Gain),
direction = "forward",
data = birthsNew,
k = 2)
forwards_reg$terms
births_lm = lm(Birth.Weight ~ 1, data = birthsNew)
library(stats)
forwards_reg = step(births_lm,
scope = list(lower = ~1, upper = ~Institution.type + Plurality.of.birth + Gender + Race.of.child + Race + Age.of.father + Age.of.mother + Education.of.father..years. + Education.of.mother..years. + Total.Preg + BDead + Terms + LOutcome + Weeks + Prenatal + Trimester.Prenatal + Visits + Birth.weight.group + Marital + Birth.Attendant + Numchild + Month.Term + Year.Term + Low.Birth + RaceMom + RaceDad + Mother.Minority + Father.Minority + HispMom + HispDad + AveCigs + Smoker + AveDrink + Wt.Gain),
direction = "forward",
data = birthsNew,
k = log(3000))
forwards_reg$terms
(956 + 964)/3000
(841 + 1066)/3000
(952 + 986)/3000
(960 + 967)/3000
(852 + 1084)/3000
(1028 + 1158)/3000
knitr::opts_chunk$set(echo = TRUE)
# set birthday seed
set.seed(0213)
# make wine data
wine = read.csv("Wine Fall 2021.csv")
dim(wine)
# make wine.color numbers to ensure compatibility
wine$Wine.Color = replace(wine$Wine.Color, wine$Wine.Color == "W", 0) # white is 0
wine$Wine.Color = replace(wine$Wine.Color, wine$Wine.Color == "R", 1) # red is 1
# split data
library(caTools)
wine_split = sample.split(wine[,14], SplitRatio = 0.70)
wine_train = wine[wine_split == TRUE,]
wine_test = wine[wine_split == FALSE,]
dim(wine_train)
dim(wine_test)
library(caret)
wine_glm = glm(as.factor(Class) ~ Wine.Color + fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
family = binomial,
data = wine_train)
# training conf matrix
wine_glm_pred = predict(wine_glm, newdata = wine_train, type = "response")
wine_glm_vec = rep("Good", 7000)
wine_glm_vec[wine_glm_pred < 0.5] = "Bad"
confusionMatrix(as.factor(wine_glm_vec), as.factor(wine_train[, 14]))
# testing conf matrix
wine_glm_pred = predict(wine_glm, newdata = wine_test, type = "response")
wine_glm_vec = rep("Good", 3000)
wine_glm_vec[wine_glm_pred < 0.5] = "Bad"
confusionMatrix(as.factor(wine_glm_vec), as.factor(wine_test[, 14]))
library(MASS)
wine_lda = lda(as.factor(Class) ~ Wine.Color + fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
data = wine_train)
# training conf matrix
wine_lda_pred = predict(wine_lda, newdata = wine_train)
confusionMatrix(as.factor(wine_lda_pred$class), as.factor(wine_train[, 14]))
# testing conf matrix
wine_lda_pred = predict(wine_lda, newdata = wine_test)
confusionMatrix(as.factor(wine_lda_pred$class), as.factor(wine_test[, 14]))
wine_qda = qda(as.factor(Class) ~ Wine.Color + fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
data = wine_train)
# training conf matrix
wine_qda_pred = predict(wine_qda, newdata = wine_train)
confusionMatrix(as.factor(wine_qda_pred$class), as.factor(wine_train[, 14]))
# testing conf matrix
wine_qda_pred = predict(wine_qda, newdata = wine_test)
confusionMatrix(as.factor(wine_qda_pred$class), as.factor(wine_test[, 14]))
library(class)
# recreate x_train but scale everything except non numeric arguments
wine_scaled_train = data.frame(X = wine_train$X, Wine.Color = wine_train$Wine.Color, scale(wine_train[, c(-1, -2, -14)]), Class = wine_train$Class)
wine_scaled_test = data.frame(X = wine_test$X, Wine.Color = wine_test$Wine.Color, scale(wine_test[, c(-1, -2, -14)]), Class = wine_test$Class)
# make knn model
wine_knn_train = knn(wine_scaled_train[, c(-1, -2, -14)], wine_scaled_train[, c(-1, -2, -14)], wine_scaled_train[, 14])
wine_knn_test = knn(wine_scaled_train[, c(-1, -2, -14)], wine_scaled_test[, c(-1, -2, -14)], wine_scaled_train[, 14])
# training conf matrix
confusionMatrix(as.factor(wine_knn_train), as.factor(wine_train[, 14]))
# testing conf matrix
confusionMatrix(as.factor(wine_knn_test), as.factor(wine_test[, 14]))
wine_log_train_acc = (2372 + 2131)/7000
wine_log_test_acc = (1005 + 901)/3000
wine_lda_train_acc = (2384 + 2123)/7000
wine_lda_test_acc = (1008 + 899)/3000
wine_qda_train_acc = (1859 + 2566)/7000
wine_qda_test_acc = (802 + 1093)/3000
wine_knn_train_acc = (3435 + 3343)/7000
wine_knn_test_acc = (1289 + 1228)/3000
# plot accuracies so it is easier to see
model_num = c(wine_log_train_acc, wine_log_test_acc, wine_lda_train_acc, wine_lda_test_acc, wine_qda_train_acc, wine_qda_test_acc, wine_knn_train_acc, wine_knn_test_acc)
plot(model_num, xlab = "Models", ylab = "Accuracy Rate", xaxt = "n")
axis(1, at = 1:8, labels = c("wine_log_train_acc", "wine_log_test_acc", "wine_lda_train_acc", "wine_lda_test_acc", "wine_qda_train_acc", "wine_qda_test_acc", "wine_knn_train_acc", "wine_knn_test_acc"))
# plot only training accuracies
model_num = c(wine_log_train_acc, wine_lda_train_acc, wine_qda_train_acc, wine_knn_train_acc)
plot(model_num, xlab = "Training Models", ylab = "Accuracy Rate", xaxt = "n")
axis(1, at = 1:4, labels = c("wine_log_train_acc", "wine_lda_train_acc", "wine_qda_train_acc", "wine_knn_train_acc"))
# plot only testing accuracies
model_num = c(wine_log_test_acc, wine_lda_test_acc, wine_qda_test_acc, wine_knn_test_acc)
plot(model_num, xlab = "Testing Models", ylab = "Accuracy Rate", xaxt = "n")
axis(1, at = 1:4, labels = c("wine_log_test_acc", "wine_lda_test_acc", "wine_qda_test_acc", "wine_knn_test_acc"))
# create a smaller wine data set because wine is too large to function with
new_wine = wine[sample(nrow(wine), 3000),]
# create wine glm model for loocv to work
wine_glm = glm(as.factor(Class) ~ Wine.Color + fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
family = binomial,
data = new_wine)
library(boot)
wine_cv_glm = cv.glm(new_wine, wine_glm)
# create wine glm model for loocv to work
wine_glm = glm(as.factor(Class) ~ Wine.Color + fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
family = binomial,
data = new_wine)
library(boot)
wine_cv_glm = cv.glm(new_wine, wine_glm)
# create wine glm model for loocv to work
wine_glm = glm(as.factor(Class) ~ Wine.Color + fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
family = binomial,
data = new_wine)
library(boot)
wine_cv_glm = cv.glm(new_wine, wine_glm)
wine_cv_glm$delta
wine_cv10_knn = train(x = new_wine_scaled[, c(-1, -2, -14)],
y = new_wine_scaled[, 14],
method = "knn",
tuneGrid = data.frame(k = 5),
trControl = trainControl(method = "cv", number = 10),
metric = "Accuracy")
wine_cv10_knn_pred = predict(wine_cv10_knn, new_wine[, c(-1, -2, -14)])
confusionMatrix(as.factor(wine_cv10_knn_pred), as.factor(new_wine[, 14]))
wine_glm_mse = wine_cv10_glm$delta
wine_lda_acc = (960 + 967)/3000
wine_qda_acc = (852 + 1084)/3000
wine_knn_acc = (1458 + 16)/3000
# plot accuracies so it is easier to see
model_num = c(wine_lda_acc, wine_qda_acc, wine_knn_acc)
wine_glm_mse
plot(model_num, xlab = "Models", ylab = "Accuracy Rate", xaxt = "n")
axis(1, at = 1:3, labels = c("wine_lda_acc", "wine_qda_acc", "wine_knn_acc"))
wine_cv10_knn = train(x = new_wine_scaled[, c(-1, -2, -14)],
y = new_wine_scaled[, 14],
method = "knn",
tuneGrid = data.frame(k = 25),
trControl = trainControl(method = "cv", number = 10),
metric = "Accuracy")
wine_cv10_knn_pred = predict(wine_cv10_knn, new_wine[, c(-1, -2, -14)])
confusionMatrix(as.factor(wine_cv10_knn_pred), as.factor(new_wine[, 14]))
# make knn model
wine_knn_train = knn(wine_scaled_train[, c(-1, -2, -14)], wine_scaled_train[, c(-1, -2, -14)], wine_scaled_train[, 14], k = 25)
wine_knn_test = knn(wine_scaled_train[, c(-1, -2, -14)], wine_scaled_test[, c(-1, -2, -14)], wine_scaled_train[, 14], k = 25)
# training conf matrix
confusionMatrix(as.factor(wine_knn_train), as.factor(wine_train[, 14]))
install.packages("ROCR")
install.packages("corrplot")
knitr::opts_chunk$set(echo = TRUE)
# read in training dataset
HDtrain <- read.csv("HDtrainNew.csv")
library(corrplot)
library(GGally)
library(ggplot2)
library(gridExtra)
# numerical: Age, RestingBP, Cholesterol, MaxHR, Oldpeak, avg_glucose_level, bmi
vars <- data.frame(HDtrain["Age"], HDtrain["RestingBP"], HDtrain["Cholesterol"], HDtrain["MaxHR"], HDtrain["Oldpeak"], HDtrain["avg_glucose_level"], HDtrain["bmi"])
ggpairs(vars) # matrix plot
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
set.seed(1128)
P.RFall <- randomForest(as.factor(HeartDisease) ~ ., data = heart.train, ntree = 100, mtry = 4, importantce = TRUE, nodesize = 2)
library(ROCR)
pred <- prediction(pred.HD.glm.train.best, as.factor(heart.train$HeartDisease))
list(integers = integer(0))
list(integers = integer(0), doubles = numeric(0), characters = character(0))
c(0, TRUE)
c("F", F)
typeof(c(0, TRUE))
typeof(c("F", F))
typeof(F)
c(list(1), "b")
typeof(c(list(1), "b"))
typeof("b")
c(FALSE, 1L)
typeof(c(FALSE, 1L))
NULL
typeof(NaN)
is.null(NULL)
is.null(NA)
is.null()
is.null(logical(0))
NULL = NA
NULL == NA
is.na(NULL)
is.integer(NULL)
is.null(NULL)
NULL = NULL
NULL == NULL
integer(0) == NULL
NULL == NULL
integer(0) == NULL
is.null(NULL)
is.logical(NULL)
logical(0) == NULL
logical(0) == NULL
?NULL
?NULL
?logical(0)
?`NULL-class
?`NULL-class`
?`NULL-object`
?NULL
logical(0) == NULL
c(logical(0)) == NULL
names$h
trees$ha
trees$this_will_be_null
trees$this_will_be_null_bc_it_does_not_exist
logical(0) == NULL
TRUE + NULL
TRUE == NULL
is.null(TRUE)
NULL == NULL
trees$this_will_be_null_bc_it_does_not_exist
trees$this_will_be_null_bc_it_does_not_exist
NULL == NULL
trees$this_will_be_null_bc_it_does_not_exist
NULL == NULL
trees$this_will_be_null_bc_it_does_not_exist
c(TRUE, FALSE, NULL)
c(TRUE, FALSE, NA)
length(c(TRUE, FALSE, NA))
typeof(c(TRUE, FALSE, NA))
length(c(TRUE, FALSE, NA))
typeof(c(TRUE, FALSE, NA))
l1 <- list(letters[1:5], letters[3:9] , letters[4:7])
l1
l2 <- list( c(letters[1:5], letters[3:9]), letters[4:7] )
l2
l1 <- list(letters[1:5], letters[3:9] , letters[4:7])
l1
print("seperator")
l2 <- list( c(letters[1:5], letters[3:9]), letters[4:7] )
l2
l1 <- list(letters[1:5], letters[3:9] , letters[4:7])
l1
print("l1 above, l2 below")
l2 <- list( c(letters[1:5], letters[3:9]), letters[4:7] )
l2
length(l1)
length(l2)
l2 <- list( c(letters[1:5], letters[3:9]), letters[4:7] )
l2
l1 <- list(letters[1:5], letters[3:9] , letters[4:7])
l1
c("h", "i")
l1[[2]][6]
l1
c(l1[[2]][6:7])
c("h","i")
l1[[2]][6:7]
l2
l2[[1]][(lengthl2[[1]] - 1): lengthl2[[1]]]
l2[[1]][(length(l2[[1]]) - 1): lengthl2[[1]]]
l2[[1]][(length(l2[[1]]) - 1): length(l2[[1]]])
l2
l2[[1]][11:12]
c(4:7) * c(2:4)
cat(5 + 6)
print(5 + 6)
x8 <- cat(5 + 6)
y8 <- print(5 + 6)
x8
y8
cat(letters[1:3], letters[24:26])
print(letters[1:3], letters[24:26]) # Why are we getting the following error?
# Error in print.default(letters[1:3], letters[24:26]) : invalid 'digits' argument
cat(l1)
print(l1)
?cat
?print
?cat
f1 <- factor(c("A","A","B","C","D","A","C"))
f1
levels(f1) <- rev(levels(f1))
f1
l1
cat(letters[1:3], letters[24:26])
print(l1)
cat(letters[1:3], letters[24:26])
print(letters[1:3], letters[24:26]) # Why are we getting the following error?
# Error in print.default(letters[1:3], letters[24:26]) : invalid 'digits' argument
cat(l1)
print(l1)
cat(letters[1:3], letters[24:26])
print(letters[1:3], letters[24:26]) # Why are we getting the following error?
# Error in print.default(letters[1:3], letters[24:26]) : invalid 'digits' argument
cat(l1)
print(l1)
cat(letters[1:3], letters[24:26])
print(letters[1:3], letters[24:26]) # Why are we getting the following error?
# Error in print.default(letters[1:3], letters[24:26]) : invalid 'digits' argument
cat(l1)
print(l1)
c(letters[1:3], letters[24:26])
letters[26]
letters[25]
letters[27]
print(1)
return 1
return
print(1)
return(1)
return(1)
cat(5 + 6)
print(5 + 6)
x8 <- cat(5 + 6)
y8 <- print(5 + 6)
x8
x9
x = c(TRUE, TRUE, NA, FALSE)
is.na(x)
vec = c(4.6, 4, 6.2)
vec[vec %% 1 == 0 & !is.na(vec)]
vec = c(4.6, 4, 6.2, NA)
vec[vec %% 1 == 0 & !is.na(vec)]
vec = c(4.6, 4, 6.2, NA)
vec[vec %% 1 == 0 & is.na(vec)]
vec = c(4.6, 4, 6.2, NA)
vec[vec %% 1 == 0 & is.na(vec)]
vec = c(4.6, 4, 6.2, NA)
vec[vec %% 1 == 0 & !is.na(vec)]
vec[vec %% 1 == 0] & !is.na(vec)
vec = c(4.6, 4, 6.2, NA)
vec[vec %% 1 == 0 & !is.na(vec)]
vec[vec %% 1 == 0]
vec[vec %% 1 == 0 & !is.na(vec)]
vec = c(4.6, 4, 6.2, NA)
vec[vec %% 1 != 0 & !is.na(vec)]
vec = c(4.6, 6.2, NA)
vec[vec %% 1 == 0 & !is.na(vec)]
NULL == NULL # this will give logical 0
trees$this_will_be_null_bc_it_does_not_exist # this will give null
length(c(TRUE, FALSE, NA))
typeof(c(TRUE, FALSE, NA))
l1 <- list(letters[1:5], letters[3:9] , letters[4:7])
l1
l1[[2]][6:7]
l2 <- list( c(letters[1:5], letters[3:9]), letters[4:7] )
l2
l2[[1]][11:12]
as.numeric(letters[24:26])
letters[24:26]
as.numeric(x)
as.numeric("x")
list(letters[1:3], letters[24:26]))
list(letters[1:3], letters[24:26])
print(list(letters[1:3], letters[24:26]))
print(l1)
f1 <- factor(c("A","A","B","C","D","A","C"))
f1
f2 <- factor(rev(c("A","A","B","C","D","A","C")))
f2
f3 <- factor(c("A","A","B","C","D","A","C"), levels = rev(c("A","B","C","D")))
f3
rev(c("A","A","B","C","D","A","C"))
sort(f3)
sort(f1)
sort(f2)
sort(f1)
sort(f2)
sort(f1)
sort(f3)
data.frame(numbers = c(1, 2, 3, 4, 5),
strings = c("one", "two", "three", "four", "five"))
simple_df = data.frame(numbers = c(1, 2, 3, 4, 5),
strings = c("one", "two", "three", "four", "five"))
as.matrix(simple_df)
c(1, TRUE) %% 1 == 0
setwd("~/Desktop/Predicting-Music-Popularity")
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
tracks = read.csv("tracks.csv")
names(tracks)
dim(tracks)
sum(is.na(tracks))
column.types = c()
for (i in 1:ncol(tracks)) {
column.types = append(column.types, typeof(tracks[, i]))
}
column.types
tracks = tracks[, !names(tracks) %in% c("id", "name")] # drop column names by their names
names(tracks)
column.types = c()
for (i in 1:ncol(tracks)) {
column.types = append(column.types, typeof(tracks[, i]))
}
column.types
numeric.cols = names(tracks)[column.types != "character"]
numeric.cols
ggplot(tracks, aes(x = duration_ms)) + geom_density(aes(color = popularity))
library(ggplot2)
library(gridExtra)
ggplot(tracks, aes(x = duration_ms)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = numeric.cols[2])) + geom_density(aes(color = popularity))
library(ggplot2)
library(gridExtra)
ggplot(tracks, aes(x = numeric.cols[2])) + geom_density(aes(color = popularity))
duration_ms
ggplot(tracks, aes(x = duration_ms)) + geom_density(aes(color = popularity))
library(ggplot2)
library(gridExtra)
ggplot(tracks, aes(x = duration_ms)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = explicit)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = danceability)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = energy)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = key)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = loudness)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = mode)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = speechiness)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = acousticness)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = instrumentalness)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = liveness)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = valence)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = tempo)) + geom_density(aes(color = popularity))
ggplot(tracks, aes(x = time_signature)) + geom_density(aes(color = popularity))
View(tracks)
unique(tracks$explicit)
unique(tracks$explicit)
isTRUE(1)
isTRUE(0)
unique(tracks$key)
unique(tracks$key)
unique(tracks$mode)
tracks[, "explicit"]
tracks$explicit
tracks$explicit == 0
replace(tracks$explicit, tracks$explicit == 0, "Not Explicit")
replace(tracks$explicit, tracks$explicit != 0, "Explicit")
tracks$explicit = replace(tracks$explicit, tracks$explicit == 0, "Not Explicit")
tracks$explicit = replace(tracks$explicit, tracks$explicit != 0, "Explicit")
View(tracks)
unique(tracks$explicit)
unique(tracks$explicit)
tracks = read.csv("tracks.csv")
names(tracks)
dim(tracks)
sum(is.na(tracks))
column.types = c()
for (i in 1:ncol(tracks)) {
column.types = append(column.types, typeof(tracks[, i]))
}
column.types
tracks = tracks[, !names(tracks) %in% c("id", "name")] # drop column names by their names
names(tracks)
column.types = c()
for (i in 1:ncol(tracks)) {
column.types = append(column.types, typeof(tracks[, i]))
}
column.types
numeric.cols = names(tracks)[column.types != "character"]
numeric.cols
unique(tracks$explicit)
replace(tracks$explicit, tracks$explicit == 0, "Not Explicit")
unique(tracks$explicit)
replace(tracks$explicit, tracks$explicit != 0, "Explicit")
tracks$explicit = replace(tracks$explicit, tracks$explicit != 0, "Explicit")
tracks$explicit = replace(tracks$explicit, tracks$explicit == 0, "Not Explicit")
unique(tracks$explicit)
unique(tracks$key)
tracks$explicit = as.factor(tracks$explicit) # factor so easier to work with later
tracks$explicit
tracks$mode = replace(tracks$mode, tracks$mode != 0, "Major")
tracks$mode = replace(tracks$mode, tracks$mode == 0, "Minor")
unique(tracks$mode)
tracks$mode = as.factor(tracks$mode) # factor so easier to work with later
unique(tracks$instrumentalness)
head(tracks$instrumentalness)
unique(tracks$time_signature)
tracks$time_signature)
tracks$time_signature
unique(tracks$time_signature)
seq_len(ncol(tracks))
